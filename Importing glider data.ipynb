{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "white-ballot",
   "metadata": {},
   "source": [
    "# Import and filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe95615",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import glidertools as gt\n",
    "import xarray as xr # for file I/O\n",
    "from cmocean import cm as cmo  # we use this for colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30db61",
   "metadata": {},
   "source": [
    "## Working with Seaglider base station files\n",
    "\n",
    "GliderTools supports loading Seaglider files, including `scicon` data (different sampling frequencies).  \n",
    "There is a function that makes it easier to find variable names that you'd like to load: `gt.load.seaglider_show_variables`  \n",
    "\n",
    "This function is demonstrated in the cell below.\n",
    "The function accepts a **list of file names** and can also receive a string with a wildcard placeholder (`*`) and basic regular expressions are also supported. In the example below we use a simple asterisk placeholder for all the files. \n",
    "\n",
    "Note that the function chooses only one file from the passed list or glob string - this file name will be shown. The returned table shows the variable name, dimensions, units and brief comment if it is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = 'data/p*.nc'\n",
    "\n",
    "gt.load.seaglider_show_variables(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad131649",
   "metadata": {},
   "source": [
    "### Load variables\n",
    "\n",
    "From the variable listing, one can choose multiple variables to load. Note that one only needs the variable name to load the data.\n",
    "\n",
    "The `gt.load.seaglider_basestation_netCDFs` function is used to load a list of variables. It requires the filename string or list (as described above) and keys. It may be that these variables are not sampled at the same frequency. In this case, the loading function will load the sampling frequency dimensions separately. The function will try to find a time variable for each sampling frequency/dimension. \n",
    "\n",
    "#### Coordinates and automatic *time* fetching\n",
    "All associated coordinate variables will also be loaded with the data if coordinates are documented. These may included *latitude, longitude, depth* and *time* (naming may vary). If time cannot be found for a dimension, a *time* variable from a different dimension with the same number of observations is used instead.\n",
    "\n",
    "#### Merging data based on time\n",
    "If the `return_merged` is set to *True*, the function will merge the dimensions if the dimension has an associated *time* variable. \n",
    "\n",
    "The function returns a dictionary of `xarray.Datasets` - a Python package that deals with coordinate indexed multi-dimensional arrays. We recommend that you read the documentation (http://xarray.pydata.org/en/stable/) as this package is used throughout *GliderTools*. This allows the original metadata to be copied with the data. The dictionary keys are the names of the dimensions. If `return_merged` is set to *True* an additional entry under the key `merged` will be included.\n",
    "\n",
    "The structure of a dimension output is shown below. Note that the merged data will use the largest dimension as the primary dataset and the other data will be merged onto that time index. Data is linearly interpolated to the nearest time measurement of the primary index, but only by one measurement to ensure transparancy.\n",
    "\n",
    "#### Metadata handling\n",
    "If the keyword argument `keep_global_attrs=True`, the attributes from the original files (for all that are the same) are passed on to the output *Datasets* from the original netCDF attributes. The variable attributes (units, comments, axis...) are passed on by default, but can also be set to False if not wanted. GliderTools functions will automatically pass on these attributes to function outputs if a `xarray.DataArray` with attributes is given. \n",
    "All functions applied to data will also be recorded under the variable attribute `processing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'ctd_depth',\n",
    "    'ctd_time',\n",
    "    'ctd_pressure',\n",
    "    'salinity',\n",
    "    'temperature',\n",
    "    'eng_wlbb2flvmt_Chlsig',\n",
    "    'eng_wlbb2flvmt_wl470sig',\n",
    "    'eng_wlbb2flvmt_wl700sig',\n",
    "    'aanderaa4330_dissolved_oxygen',\n",
    "    'eng_qsp_PARuV',\n",
    "]\n",
    "\n",
    "ds_dict = gt.load.seaglider_basestation_netCDFs(filenames, names, return_merged=True, keep_global_attrs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we drop the time variables imported for the PAR variable\n",
    "# we don't need these anymore. You might have to change this \n",
    "# depening on the dataset\n",
    "merged = ds_dict['merged']\n",
    "if 'time' in merged:\n",
    "    merged = merged.drop([\"time\", \"time_dt64\"])\n",
    "\n",
    "\n",
    "# To make it easier and clearer to work with, we rename the \n",
    "# original variables to something that makes more sense. This\n",
    "# is done with the xarray.Dataset.rename({}) function.\n",
    "# We only use the merged dataset as this contains all the \n",
    "# imported dimensions. \n",
    "# NOTE: The renaming has to be specific to the dataset otherwise an error will occur\n",
    "dat = merged.rename({\n",
    "    'salinity': 'salt_raw',\n",
    "    'temperature': 'temp_raw',\n",
    "    'ctd_pressure': 'pressure',\n",
    "    'ctd_depth': 'depth',\n",
    "    'ctd_time_dt64': 'time',\n",
    "    'ctd_time': 'time_raw',\n",
    "    'eng_wlbb2flvmt_wl700sig': 'bb700_raw',\n",
    "    'eng_wlbb2flvmt_wl470sig': 'bb470_raw',\n",
    "    'eng_wlbb2flvmt_Chlsig': 'flr_raw',\n",
    "    'eng_qsp_PARuV': 'par_raw',\n",
    "    'aanderaa4330_dissolved_oxygen': 'oxy_raw',\n",
    "})\n",
    "\n",
    "print(dat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be113058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable assignment for conveniant access\n",
    "depth = dat.depth\n",
    "dives = dat.dives\n",
    "lats = dat.latitude\n",
    "lons = dat.longitude\n",
    "time = dat.time\n",
    "pres = dat.pressure\n",
    "temp = dat.temp_raw\n",
    "salt = dat.salt_raw\n",
    "\n",
    "# name coordinates for quicker plotting\n",
    "x = dat.dives\n",
    "y = dat.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9052e",
   "metadata": {},
   "source": [
    "Glidertools has inbuild plotting routines for data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.plot(x, y, salt, cmap=cmo.haline, robust=True, shading='auto')\n",
    "title('Original Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89786430",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "The `cleaning` module contains several tools that help to remove erroneous data - profiles or points. \n",
    "These filters can be applied *globally* (IQR and standard devation limits), *vertically* (running average filters) or *horizontally* (horizontal filters on gridded data only). \n",
    "\n",
    "Below we use **salinity** to demonstrate the different functions available to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a64d07",
   "metadata": {},
   "source": [
    "## Global filtering: outlier limits \n",
    "These functions find upper and lower limits for data outliers using standard deviations of the entire dataset. Multipliers can be set to make the filters more or less strict. Alternatively, data can be filtered by interquartile range using `outlier_bounds_iqr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_std = gt.cleaning.outlier_bounds_std(salt, multiplier=2)\n",
    "gt.plot(x, y, salt_std, cmap=cmo.haline, robust=True, shading='flat')\n",
    "title('Outlier Bounds Stdev Method')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b8132",
   "metadata": {},
   "source": [
    "#### Despiking\n",
    "This approach was used by Briggs et al. (2010). The idea is to apply a rolling filter to the data (along the time dimension). This forms the baseline. The difference from the original data are spikes. \n",
    "\n",
    "There are two rolling filters that can be applied to the data. The *median* approach is the equivalent of a rolling median. The *minmax* approach first applies a rolling minimum and then rolling maximum to data. This is useful particularly for optics data where spikes are particles in the water column and are not normally distributed. \n",
    "\n",
    "Here we use the median filter for salinity. Custom rolling filters can be applied created with the `gt.cleaning.rolling_window` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_base, salt_spike = gt.cleaning.despike(salt, window_size=5, spike_method='median')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=[9, 6], sharex=True, dpi=90)\n",
    "\n",
    "gt.plot(x, y, salt_base, cmap=cmo.haline, ax=ax[0])\n",
    "ax[0].set_title('Despiked using median filter')\n",
    "ax[0].cb.set_label('Salinity despiked')\n",
    "ax[0].set_xlabel('')\n",
    "\n",
    "gt.plot(x, y, salt_spike, cmap=cm.RdBu_r, vmin=-6e-3, vmax=6e-3, ax=ax[1])\n",
    "ax[1].cb.set_label('Salinity spikes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326ee2d",
   "metadata": {},
   "source": [
    "### Savitzky-Golay \n",
    "The Savitzky-Golay function fits a low order polynomial to a rolling window of the time series. This has the result of smoothing the data. A larger window with a lower order polynomial with have a smoother fit.\n",
    "\n",
    "We recommend a 2nd order kernel. Here we use first order to show that the difference can be quite big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_savgol = gt.cleaning.savitzky_golay(salt, window_size=11, order=1)\n",
    "fig, ax = plt.subplots(2, 1, figsize=[9, 6], sharex=True, dpi=90)\n",
    "\n",
    "gt.plot(x, y, salt_savgol, cmap=cmo.haline, ax=ax[0])\n",
    "ax[0].set_title('Smoothing the data with Savitzky-Golay')\n",
    "ax[0].cb.set_label('Smoothed salinity')\n",
    "ax[0].set_xlabel('')\n",
    "\n",
    "gt.plot(x, y, salt_savgol - salt, cmap=cm.RdBu, vmin=-6e-3, vmax=6e-3, ax=ax[1])\n",
    "ax[1].cb.set_label('Difference from original');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c001955",
   "metadata": {},
   "source": [
    "Several filtering steps can be applied with a single function call using the `gt.calc_physics` wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f13d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_qc = gt.calc_physics(salt, x, y, \n",
    "                          mask_frac=0.2, iqr=2.5, \n",
    "                          spike_window=5, spike_method='median', \n",
    "                          savitzky_golay_window=11, savitzky_golay_order=2)\n",
    "        \n",
    "fig, ax = plt.subplots(3, 1, figsize=[9, 8.5], sharex=True, dpi=90)\n",
    "\n",
    "gt.plot(x, y, salt, cmap=cmo.haline, ax=ax[0])\n",
    "gt.plot(x, y, salt_qc, cmap=cmo.haline, ax=ax[1])\n",
    "gt.plot(x, y, salt_qc - salt, cmap=cm.RdBu_r, vmin=-0.02, vmax=0.02, ax=ax[2])\n",
    "\n",
    "[a.set_xlabel('') for a in ax]\n",
    "\n",
    "ax[0].cb.set_label('Original Data')\n",
    "ax[1].cb.set_label('Cleaned Data')\n",
    "ax[2].cb.set_label('Difference from Original')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed3b3f",
   "metadata": {},
   "source": [
    "### Effect of cleaning on a single data profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c36c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots(1, 3, figsize=[10, 5], dpi=90)\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "dive_no = 310.5\n",
    "\n",
    "idx = dat.dives==dive_no\n",
    "colors = rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].plot(salt[idx],         y[idx], c=colors[0], label='Raw', lw=4)\n",
    "    ax[i].plot(salt_base[idx],    y[idx], c=colors[3], label='Despike window = 3')\n",
    "    ax[i].plot(salt_savgol[idx],  y[idx], c='k', label='Savitsky-Golay')\n",
    "    \n",
    "ax[2].barh(y[idx], salt_savgol[idx]  - salt[idx], zorder=100, facecolor='k')\n",
    "ax[2].barh(y[idx], salt_base[idx]    - salt[idx], zorder=100, facecolor=colors[3])\n",
    "\n",
    "ax[0].set_xlim(34, 34.4)\n",
    "ax[1].set_xlim(34, 34.2)\n",
    "ax[0].legend(loc=4)\n",
    "\n",
    "ymin, ymax= 0, 100\n",
    "ax[0].fill_between([33, 35], [ymin, ymin], [ymax, ymax], facecolor='k', alpha=0.2)\n",
    "ax[0].set_ylim(500, 0)\n",
    "ax[1].set_ylim(ymax, ymin)\n",
    "ax[0].set_ylabel('Depth [m]', labelpad=15)\n",
    "ax[0].set_xlabel('Salinity', labelpad=15)\n",
    "ax[1].set_xlabel('Salinity', labelpad=15)\n",
    "ax[2].set_xlabel('$\\Delta$Salinity', labelpad=15)\n",
    "ax[1].set_title('Profile ' + str(dive_no))\n",
    "\n",
    "ax[2].set_ylim(ymax, ymin)\n",
    "ax[2].set_xlim(-0.01, 0.01)\n",
    "[a.grid(c='0.75', ls='--') for a in ax]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38529f45",
   "metadata": {},
   "source": [
    "### Asigning data\n",
    "\n",
    "New variables can be added to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80013ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_qc = gt.calc_physics(temp, x, y, \n",
    "                          mask_frac=0.2, iqr=2.5, \n",
    "                          spike_window=5, spike_method='median', \n",
    "                          savitzky_golay_window=11, savitzky_golay_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dede75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['salt_qc'] = salt_qc\n",
    "dat['temp_qc'] = temp_qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e74c59",
   "metadata": {},
   "source": [
    "### Saving data\n",
    "\n",
    "You can save the dat object using [xarray's netcdf read/write](https://xarray.pydata.org/en/stable/io.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_netcdf('physics_processed.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f6c93",
   "metadata": {},
   "source": [
    "This netcdf can be read using `open_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_from_file = xr.open_dataset('physics_processed.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d51490",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_from_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
